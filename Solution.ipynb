{"cells": [{"cell_type": "markdown", "id": "7460b660-51a9-4f22-a067-4b0dd3d907e4", "metadata": {}, "source": "# Importing required libraries and Creating Spark Session"}, {"cell_type": "code", "execution_count": 129, "id": "90961e6e-b2dc-4532-ae9b-14629cac1a2b", "metadata": {}, "outputs": [], "source": "# Importing Required libraries\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType, FloatType\n\n# Creating Spark Session\nSpark = SparkSession.builder.appName(\"Assignment2\").enableHiveSupport().getOrCreate()"}, {"cell_type": "code", "execution_count": 130, "id": "ce037c67-763d-4a59-8d48-32f7b795af63", "metadata": {}, "outputs": [{"data": {"text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://cluster-4caf-m.us-central1-f.c.keen-device-413016.internal:33569\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Assignment2</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ", "text/plain": "<pyspark.sql.session.SparkSession at 0x7fdc047474c0>"}, "execution_count": 130, "metadata": {}, "output_type": "execute_result"}], "source": "Spark"}, {"cell_type": "markdown", "id": "595eaa2f-5bc0-402a-9ca7-59d58760fbfa", "metadata": {}, "source": "# Setting data location"}, {"cell_type": "code", "execution_count": 131, "id": "048fb04d-6c8c-4636-9162-788c250c4175", "metadata": {}, "outputs": [], "source": "# Setting data location\nmovies = \"/Spark/Assignment2/movies.csv\"\nratings = \"/Spark/Assignment2/ratings.csv\"\ntags = \"/Spark/Assignment2/tags.csv\""}, {"cell_type": "markdown", "id": "eb14221d-306c-4dbd-94ce-42b415434ffe", "metadata": {}, "source": "# Reading Movie data,Infering schema and Creating Dataframe"}, {"cell_type": "code", "execution_count": 132, "id": "443f92ce-52f9-4bd5-acf7-0ca63dcdff3a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------+--------------------+--------------------+\n|movieId|               title|              genres|\n+-------+--------------------+--------------------+\n|      1|    Toy Story (1995)|Adventure|Animati...|\n|      2|      Jumanji (1995)|Adventure|Childre...|\n|      3|Grumpier Old Men ...|      Comedy|Romance|\n|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n|      5|Father of the Bri...|              Comedy|\n+-------+--------------------+--------------------+\nonly showing top 5 rows\n\n"}], "source": "# Reading movies data and printing sample data\nmovies_df = Spark.read.format(\"csv\").options(header = True,inferschema = True).load(movies)\nmovies_df.show(5)"}, {"cell_type": "markdown", "id": "cdbc0a17-15af-42f6-a779-07811d468239", "metadata": {}, "source": "# Reading Ratings data,Creating schema,changing timestamp column type from Integer to Timestamp and Creating Dataframe"}, {"cell_type": "code", "execution_count": 133, "id": "878b47a8-5bc5-46ee-a492-6186cc4dc952", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+-------+------+-------------------+\n|userId|movieId|rating|          timestamp|\n+------+-------+------+-------------------+\n|     1|      1|   4.0|2000-07-30 18:45:03|\n|     1|      3|   4.0|2000-07-30 18:20:47|\n|     1|      6|   4.0|2000-07-30 18:37:04|\n|     1|     47|   5.0|2000-07-30 19:03:35|\n|     1|     50|   5.0|2000-07-30 18:48:51|\n+------+-------+------+-------------------+\nonly showing top 5 rows\n\n"}], "source": "# Setting ratings data schema\nratings_schema = StructType([StructField('userId',IntegerType(),True),\n                             StructField('movieId',IntegerType(),True),\n                             StructField('rating',FloatType(),True),\n                             StructField('timestamp',IntegerType(),True)\n])\n\n# Reading ratings data and converting timestamp from int type to timestamp type and printing data\nratings_df = Spark.read.format(\"csv\").option('header','true').schema(ratings_schema).load(ratings)\nratings_df = ratings_df.withColumn(\"timestamp\",F.from_unixtime(\"timestamp\").cast(TimestampType()))\nratings_df.show(5)"}, {"cell_type": "markdown", "id": "41db0e1e-c2c7-4fd6-b843-301d07c523fa", "metadata": {}, "source": "# Reading Tags data,Creating schema,changing timestamp column type from Integer to Timestamp and Creating Dataframe"}, {"cell_type": "code", "execution_count": 134, "id": "49dabda7-6dd8-4135-8721-2d492132544c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+-------+---------------+-------------------+\n|userId|movieId|            tag|          timestamp|\n+------+-------+---------------+-------------------+\n|     2|  60756|          funny|2015-10-24 19:29:54|\n|     2|  60756|Highly quotable|2015-10-24 19:29:56|\n|     2|  60756|   will ferrell|2015-10-24 19:29:52|\n|     2|  89774|   Boxing story|2015-10-24 19:33:27|\n|     2|  89774|            MMA|2015-10-24 19:33:20|\n+------+-------+---------------+-------------------+\nonly showing top 5 rows\n\n"}], "source": "# Setting tags data schema\ntags_schema = StructType([StructField(\"userId\",IntegerType(),True),\n                          StructField(\"movieId\",IntegerType(),True),\n                          StructField(\"tag\",StringType(),True),\n                          StructField(\"timestamp\",IntegerType(),True)\n])\n\n# Reading tags data and converting timestamp from int type to timestamp type and printing data\ntags_df = Spark.read.csv(tags,header=True,schema=tags_schema)\ntags_df = tags_df.withColumn(\"timestamp\",F.from_unixtime(\"timestamp\").cast(TimestampType()))\ntags_df.show(5)"}, {"cell_type": "markdown", "id": "8eae1545-f22c-4485-b4c1-0900b7f7c7a8", "metadata": {"tags": []}, "source": "# Work with Spark SQL"}, {"cell_type": "code", "execution_count": 135, "id": "c7610f23-6ff8-4223-af1d-be3ddf4eba17", "metadata": {}, "outputs": [], "source": "movies_df.createOrReplaceTempView(\"Movies\")\nratings_df.createOrReplaceTempView(\"Ratings\")\ntags_df.createOrReplaceTempView(\"Tags\")"}, {"cell_type": "markdown", "id": "88def05d-e4dc-4f22-9311-c444625d34b8", "metadata": {"tags": []}, "source": "# 1. Show the aggregated number of ratings per year and save the data in a single CSV file in HDFS "}, {"cell_type": "code", "execution_count": 136, "id": "b109151e-fdbc-4c5a-a54a-f846032ca81c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----+-------+\n|Year|Ratings|\n+----+-------+\n|2018|   6418|\n|2017|   8198|\n|2016|   6703|\n|2015|   6616|\n|2014|   1439|\n|2013|   1664|\n|2012|   4656|\n|2011|   1690|\n|2010|   2301|\n|2009|   4158|\n|2008|   4351|\n|2007|   7114|\n|2006|   4059|\n|2005|   5813|\n|2004|   3279|\n|2003|   4014|\n|2002|   3478|\n|2001|   3922|\n|2000|  10061|\n|1999|   2439|\n+----+-------+\nonly showing top 20 rows\n\nSaved Successfully\n"}], "source": "# Aggregated number of ratings per year\nQuery = \"\"\" SELECT Year(timestamp) as Year, Count(rating) AS Ratings\n            FROM Ratings\n            GROUP BY Year\n            ORDER BY Year DESC; \"\"\"\nOutput = Spark.sql(Query)\nOutput.show()\n\n# Write data in HDFS into single file\nOutput.coalesce(1).write.mode(\"overwrite\").format('csv').option('header', 'true') .option('delimiter', ',').save(\"/Spark/Assignment2/Solution/agg_ratings_yearly.csv\")\nprint(\"Saved Successfully\")"}, {"cell_type": "markdown", "id": "c339612d-fbb2-4f39-bff3-286175b1f804", "metadata": {}, "source": "# 2. Show the average monthly number of ratings and save the data in a single CSV file in HDFS"}, {"cell_type": "code", "execution_count": 137, "id": "e2ee3412-7bf1-4c55-8651-3bdd532c1a71", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------+-------+\n|  Month|Ratings|\n+-------+-------+\n|2018-09|    604|\n|2018-08|    831|\n|2018-07|    293|\n|2018-06|    419|\n|2018-05|    951|\n|2018-04|    230|\n|2018-03|    971|\n|2018-02|   1169|\n|2018-01|    950|\n|2017-12|    536|\n|2017-11|    230|\n|2017-10|    225|\n|2017-09|    424|\n|2017-08|    221|\n|2017-07|    170|\n|2017-06|   1910|\n|2017-05|   2397|\n|2017-04|    923|\n|2017-03|    549|\n|2017-02|    420|\n+-------+-------+\nonly showing top 20 rows\n\nSaved Successfully\n"}], "source": "# Average monthly number of ratings\nQuery =  \"\"\" SELECT left(timestamp,7) as Month, Count(rating) AS Ratings \n            FROM Ratings\n            GROUP BY Month \n            ORDER BY Month DESC; \"\"\"\n\nOutput = Spark.sql(Query)\nOutput.show()\n# Write data in HDFS into single file\nOutput.coalesce(1).write.mode(\"overwrite\").format('csv').options(header = True,delimiter = ',').save(\"/Spark/Assignment2/Solution/agg_ratings_monthly.csv\")\nprint(\"Saved Successfully\")"}, {"cell_type": "markdown", "id": "129230e4-6902-4cba-a45b-5d0b1f7ed425", "metadata": {}, "source": "# 3. Show the ratings count and save the data in a single CSV file in HDFS"}, {"cell_type": "code", "execution_count": 138, "id": "2ce8160b-af21-4c0d-be77-2b543eb48a85", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+------+\n|rating|Counts|\n+------+------+\n|   0.5|  1370|\n|   1.0|  2811|\n|   1.5|  1791|\n|   2.0|  7551|\n|   2.5|  5550|\n|   3.0| 20047|\n|   3.5| 13136|\n|   4.0| 26818|\n|   4.5|  8551|\n|   5.0| 13211|\n+------+------+\n\nSaved Successfully\n"}], "source": "# rating counts\n\nQuery = \"\"\" SELECT rating, COUNT(rating) as Counts\n            FROM Ratings\n            Group by rating\n            ORDER BY rating; \"\"\"\nOutput = Spark.sql(Query)\nOutput.show()\n\n# Write data in HDFS into single file\nOutput.coalesce(1).write.mode(\"overwrite\").format(\"csv\").options(header = True,delimiter = ',').save(\"/Spark/Assignment2/Solution/ratings_count.csv\")\nprint(\"Saved Successfully\")"}, {"cell_type": "markdown", "id": "cedc1ef4-74a7-4af6-aa42-318e80e9226b", "metadata": {}, "source": "# 4. Show the rating levels distribution and save the data in a single CSV file in HDFS"}, {"cell_type": "code", "execution_count": 139, "id": "7f8873bc-c5a0-406a-bcb6-47ee59e23ad4", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/02/17 20:39:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"}, {"name": "stdout", "output_type": "stream", "text": "+-------------+------+------------------+\n|Rating_Bucket|Counts|        Percentage|\n+-------------+------+------------------+\n|    0.0 - 2.0| 13523|13.410885001388394|\n|    2.5 - 3.5| 38733| 38.41187671069856|\n|    4.0 - 5.0| 48580| 48.17723828791305|\n+-------------+------+------------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "24/02/17 20:39:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"}, {"name": "stdout", "output_type": "stream", "text": "Saved Successfully\n"}], "source": "# rating levels distribution\n\nQuery = \"\"\" WITH T1 AS (\n            SELECT rating,\n            CASE WHEN rating >= 0 AND rating < 2.5 THEN '0.0 - 2.0'\n            WHEN rating >= 2.5 AND rating < 4.0 THEN '2.5 - 3.5'\n            ELSE '4.0 - 5.0' END AS Rating_Bucket \n            FROM Ratings),\n            \n            T2 AS (SELECT Rating_Bucket, Count(rating) as Counts\n            FROM T1 \n            GROUP BY Rating_Bucket\n            ORDER BY Rating_Bucket)\n            \n            SELECT Rating_Bucket, Counts, Counts*100/SUM(Counts)OVER() AS Percentage\n            FROM T2 \"\"\"\n\nOutput = Spark.sql(Query)\nOutput.show()\n\n# Write data in HDFS into single file\nOutput.coalesce(1).write.mode(\"overwrite\").format(\"csv\").options(header = True,delimiter = ',').save(\"/Spark/Assignment2/Solution/rating_level_distribution.csv\")\nprint(\"Saved Successfully\")"}, {"cell_type": "markdown", "id": "7e52a61b-377b-4c63-b6cf-f48326e783fe", "metadata": {}, "source": "# 5. Show the movies that have tag but no rating and save the data in a single CSV file in HDFS"}, {"cell_type": "code", "execution_count": 140, "id": "e92d836a-94f9-4734-830f-4f4527816a8c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|               title|\n+--------------------+\n|Browning Version,...|\n|Call Northside 77...|\n|  Chalet Girl (2011)|\n|  Chosen, The (1981)|\n|Color of Paradise...|\n|For All Mankind (...|\n|I Know Where I'm ...|\n|In the Realms of ...|\n|Innocents, The (1...|\n|Mutiny on the Bou...|\n|      Niagara (1953)|\n|Parallax View, Th...|\n|        Proof (1991)|\n|Road Home, The (W...|\n|Roaring Twenties,...|\n|      Scrooge (1970)|\n|This Gun for Hire...|\n|Twentieth Century...|\n+--------------------+\n\nsaved Successfully\n"}], "source": "# movies that have tag but no rating\n\nQuery = \"\"\" WITH T1 AS(SELECT DISTINCT(T.movieId) FROM Tags T \n            LEFT JOIN Ratings R ON \n            T.movieId = R.movieId\n            WHERE R.movieID is NULL)\n            \n            SELECT M.title FROM Movies M\n            INNER JOIN T1 ON T1.movieId = M.movieId \n            ORDER BY M.title\"\"\"\nOutput = Spark.sql(Query)\nOutput.show()\n\n# Write data in HDFS into single file\nOutput.coalesce(1).write.mode(\"overwrite\").format(\"csv\").options(header = True, delimiter = ',').save(\"/Spark/Assignment2/Solution/movies_without_ratings.csv\")\nprint(\"saved Successfully\")"}, {"cell_type": "markdown", "id": "3f6c18f3-4127-4b38-a623-ee14c69dfb0b", "metadata": {}, "source": "# 6. Show the movies that have rating but no tag and save the data in a single CSV file in HDFS"}, {"cell_type": "code", "execution_count": 141, "id": "acbf460a-1f47-4ec9-a739-1d4a3fa4e9fd", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|               title|\n+--------------------+\n|          '71 (2014)|\n|'Hellboy': The Se...|\n|'Round Midnight (...|\n| 'Salem's Lot (2004)|\n|'Til There Was Yo...|\n|'Tis the Season f...|\n|  'burbs, The (1989)|\n|'night Mother (1986)|\n|*batteries not in...|\n|...All the Marble...|\n|00 Schneider - Ja...|\n|   1-900 (06) (1994)|\n|           10 (1979)|\n|10 Cent Pistol (2...|\n|10 Items or Less ...|\n|     10 Years (2011)|\n|    10,000 BC (2008)|\n|    100 Girls (2000)|\n|  100 Streets (2016)|\n|101 Dalmatians II...|\n+--------------------+\nonly showing top 20 rows\n\nsaved Successfully\n"}], "source": "# movies that have rating but no tag\n\nQuery = \"\"\" WITH T1 AS(SELECT DISTINCT(R.movieId) FROM Tags T \n            RIGHT JOIN Ratings R ON \n            T.movieId = R.movieId\n            WHERE T.movieID is NULL)\n            \n            SELECT M.title FROM Movies M\n            INNER JOIN T1 ON T1.movieId = M.movieId \n            ORDER BY M.title\"\"\"\nOutput = Spark.sql(Query)\nOutput.show()\n\n# Write data in HDFS into single file\nOutput.coalesce(1).write.mode(\"overwrite\").format(\"csv\").options(header = True, delimiter = ',').save(\"/Spark/Assignment2/Solution/movies_without_tags.csv\")\nprint(\"saved Successfully\")"}, {"cell_type": "markdown", "id": "fdac8c1f-23f8-431c-87da-2ab63a353bd5", "metadata": {}, "source": "# 7. Focusing on the rated untagged movies with more than 30 user ratings, show the top 10 movies in terms of average rating and number of ratings and save the data in a single CSV file in HDFS"}, {"cell_type": "code", "execution_count": 142, "id": "910ba37b-531d-42a3-aaf3-00c3d00c157d", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+-----------------+-----------+--------------------+-----------+---------+\n|         MovieTitle1|    AverageRating|AverageRank|         MovieTitle2|CountRating|CountRank|\n+--------------------+-----------------+-----------+--------------------+-----------+---------+\n|Boondock Saints, ...| 4.22093023255814|          1|American Beauty (...|        204|        1|\n|       Brazil (1985)|4.177966101694915|          2|Ace Ventura: Pet ...|        161|        2|\n|Cinema Paradiso (...|4.161764705882353|          3|    Mask, The (1994)|        157|        3|\n|       Snatch (2000)|4.155913978494624|          4|     Die Hard (1988)|        145|        4|\n|For a Few Dollars...|4.151515151515151|          5|Die Hard: With a ...|        144|        5|\n|Lives of Others, ...|4.117647058823529|          6|Groundhog Day (1993)|        143|        6|\n|  Toy Story 3 (2010)|4.109090909090909|          7|Dumb & Dumber (Du...|        133|        7|\n|Boogie Nights (1997)|4.076923076923077|          8|Monsters, Inc. (2...|        132|        8|\n|Boogie Nights (1997)|4.076923076923077|          8|    GoldenEye (1995)|        132|        8|\n|American Beauty (...|4.056372549019608|          9|Austin Powers: Th...|        121|        9|\n|Lock, Stock & Two...|4.052238805970149|         10|Willy Wonka & the...|        119|       10|\n+--------------------+-----------------+-----------+--------------------+-----------+---------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/02/17 20:39:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"}, {"name": "stdout", "output_type": "stream", "text": "Saved Successfully\n"}], "source": "#Focusing on the rated untagged movies with more than 30 user ratings, show the top 10 movies in terms of average rating and number of ratings\n\nQuery = \"\"\" WITH T1 AS (\n                SELECT movieId FROM Ratings\n                GROUP BY movieId\n                HAVING COUNT(DISTINCT userId) > 30),\n            T2 AS ( SELECT T1.movieId FROM T1 \n                    LEFT JOIN Tags T\n                    ON T1.movieId = T.movieId\n                    WHERE  T.movieId is NULL),\n            T3 AS ( SELECT M.Title, M.movieId FROM Movies M\n                    INNER JOIN T2 ON \n                    M.movieId = T2.movieId\n                    ORDER BY 1),\n            T4 AS ( SELECT T3.title, AVG(R.rating) as avg_rating,\n                    DENSE_RANK() OVER(ORDER BY AVG(R.rating) DESC) AS avg_rank\n                    FROM T3 LEFT JOIN \n                    Ratings R ON T3.movieId = R.movieId\n                    GROUP BY 1),\n            T5 AS ( SELECT T3.title, COUNT(R.rating) AS rating_count,\n                    DENSE_RANK() OVER(ORDER BY COUNT(R.rating) DESC) AS count_rank\n                    FROM T3 LEFT JOIN \n                    Ratings R ON T3.movieId = R.movieId\n                    GROUP BY 1)\n            SELECT T4.title as MovieTitle1, T4.avg_rating AS AverageRating, T4.avg_rank as AverageRank,\n            T5.title AS MovieTitle2, T5.rating_count as CountRating , T5.count_rank AS CountRank\n            FROM T4 INNER JOIN T5 ON \n            T4.avg_rank = T5.count_rank\n            WHERE T4.avg_rank <= 10 AND T5.count_rank <= 10 \"\"\"\n\nOutput = Spark.sql(Query)\nOutput.show()\n# Write data in HDFS into single file\nOutput.coalesce(1).write.mode(\"overwrite\").format(\"csv\").options(header = True, delimiter = ',').save(\"/Spark/Assignment2/Solution/Top_10_Average_Ratings&Count_Ratings.csv\")\nprint(\"Saved Successfully\")"}, {"cell_type": "markdown", "id": "837f8e70-23c3-4656-8d4e-c51c65dc304b", "metadata": {}, "source": "# 8. What is the average number of tags per movie in tagsDF? And the average number of tags per user? How does it compare with the average number of tags a user assigns to a movie? \n# save the data in a single CSV file in HDFS"}, {"cell_type": "code", "execution_count": 143, "id": "b65b8baf-514e-49fd-9183-7714b26c6031", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------------------+---------------------+\n|Average_Tags_Per_Movie|Average_Tags_Per_User|\n+----------------------+---------------------+\n|    2.3428753180661577|                 63.5|\n+----------------------+---------------------+\n\nSaved Successfully\n"}], "source": "# What is the average number of tags per movie in tagsDF? And the average number of tags per user? How does it compare with the average number of tags a user assigns to a movie?\n\nQuery = \"\"\" WITH T1 AS\n                ( SELECT movieId, COUNT(tag) AS MovieTags\n                FROM Tags\n                GROUP BY movieId\n                ORDER BY movieId ),\n            T2 AS \n                ( SELECT userId, COUNT(tag) AS UserTags\n                FROM Tags\n                GROUP BY userId\n                ORDER BY userId )\n            \n            SELECT AVG(MovieTags) AS Average_Tags_Per_Movie,AVG(UserTags) AS Average_Tags_Per_User FROM T1,T2 \"\"\"\n\nOutput = Spark.sql(Query)\nOutput.show()\n\n# Write data in HDFS into single file\nOutput.coalesce(1).write.mode(\"overwrite\").format(\"csv\").options(header = True,delimiter = ',').save(\"/Spark/Assignment2/Solution/Average_Tags_Per_Movie&User.csv\")\nprint(\"Saved Successfully\")"}, {"cell_type": "markdown", "id": "b4bee724-8c2e-47cb-82c6-574e3728ae41", "metadata": {}, "source": "# 9. Identify the users that tagged movies without rating them and save the data in a single CSV file in HDFS"}, {"cell_type": "code", "execution_count": 144, "id": "06a0ba42-b7f1-485e-8729-7754c2216589", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+\n|userId|\n+------+\n|   474|\n|   318|\n|   543|\n|   288|\n+------+\n\nSaved Successfully\n"}], "source": "# Identify the users that tagged movies without rating them\n\nQuery = \"\"\" SELECT DISTINCT T.userId FROM Tags T \n                LEFT JOIN Ratings R \n                ON T.movieId = R.movieId\n                WHERE R.userId IS NULL \"\"\"\n\nOutput = Spark.sql(Query)\nOutput.show()\n\n# Write data in HDFS into single file\nOutput.coalesce(1).write.mode(\"overwrite\").format(\"csv\").options(header = True, delimiter = ',').save(\"/Spark/Assignment2/Solution/User_tags_Without_Ratings.csv\")\nprint(\"Saved Successfully\")"}, {"cell_type": "markdown", "id": "2b4efc1c-725a-44f7-a670-c3148716b768", "metadata": {}, "source": "# 10.What is the average number of ratings per user in ratings DF? And the average number of ratings per movie? save the data in a single CSV file in HDFS"}, {"cell_type": "code", "execution_count": 145, "id": "9b6e3660-8c55-406d-980c-95c4e7c3afda", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------------------------+-------------------------+\n|Average_Ratings_Per_User|Average_Ratings_Per_Movie|\n+------------------------+-------------------------+\n|      165.30491803278687|       10.369806663924312|\n+------------------------+-------------------------+\n\nSaved Successfully\n"}], "source": "# What is the average number of ratings per user in ratings DF? And the average number of ratings per movie?\nQuery = \"\"\" WITH T1 AS \n                ( SELECT COUNT(*)/COUNT(DISTINCT userId) AS Average_Ratings_Per_User \n                FROM Ratings ),\n            T2 AS\n                ( SELECT COUNT(*)/COUNT(DISTINCT movieId) AS Average_Ratings_Per_Movie\n                FROM Ratings )\n            \n            SELECT * FROM T1,T2 \"\"\"\n\nOutput = Spark.sql(Query)\nOutput.show()\n\n# Write data in HDFS into single file\nOutput.coalesce(1).write.mode(\"overwrite\").format(\"csv\").options(header = True, delimiter = ',').save(\"/Spark/Assignment2/Solution/Average_Ratings_Per_User&Movie.csv\")\nprint(\"Saved Successfully\")"}, {"cell_type": "markdown", "id": "6106fb5f-30eb-4117-9169-fa27c4c53833", "metadata": {}, "source": "# 11. What is the predominant (frequency based) genre per rating level? save the data in a single CSV file in HDFS"}, {"cell_type": "code", "execution_count": 146, "id": "17e58b82-0039-48de-81ae-968c0e67fec0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+------+------+\n|Rating| Genre|Counts|\n+------+------+------+\n|   5.0| Drama|   895|\n|   4.5| Drama|   593|\n|   4.0| Drama|  2055|\n|   3.5|Comedy|   854|\n|   3.0|Comedy|  1614|\n|   2.5|Comedy|   515|\n|   2.0|Comedy|   828|\n|   1.5|Comedy|   256|\n|   1.0|Comedy|   348|\n|   0.5|Comedy|   136|\n+------+------+------+\n\nSaved Successfully\n"}], "source": "# What is the predominant (frequency based) genre per rating level?\nQuery = \"\"\" WITH T1 AS \n                ( SELECT R.rating AS Rating, M.genres AS Genre, COUNT(R.rating) AS Counts,\n                DENSE_RANK() OVER(Partition BY R.rating ORDER BY COUNT(R.rating) DESC) AS Rank\n                FROM Ratings R \n                INNER JOIN Movies M \n                ON M.movieId = R.movieId \n                GROUP BY Rating,Genre\n                ORDER BY Counts DESC,Rating )\n                \n                SELECT T1.Rating, T1.Genre, T1.Counts FROM T1 WHERE Rank = 1\n                ORDER BY T1.Rating DESC \"\"\"\n\nOutput = Spark.sql(Query)\nOutput.show()\n\n# Write data in HDFS into single file\nOutput.coalesce(1).write.mode(\"overwrite\").format(\"csv\").options(header = True,delimiter = ',').save(\"/Spark/Assignment2/Solution/Frequency_Based_Genre_Per_Rating.csv\")\n\nprint(\"Saved Successfully\")\n\n"}, {"cell_type": "markdown", "id": "5b7d1449-8e4f-484a-844b-8783560d2651", "metadata": {}, "source": "# 12. What is the predominant tag per genre and the most tagged genres? save the data in a single CSV file in HDFS"}, {"cell_type": "code", "execution_count": 147, "id": "26a42775-f842-434c-bd8c-9c41a4bc748f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------+--------------------+\n|           Tag|               Genre|\n+--------------+--------------------+\n|          null|             Western|\n|          null|                 War|\n|          null|            Thriller|\n|          null|Sci-Fi|Thriller|IMAX|\n|          null|     Sci-Fi|Thriller|\n|   time-travel|         Sci-Fi|IMAX|\n|        sci-fi|         Sci-Fi|IMAX|\n|          null|              Sci-Fi|\n|          null|     Romance|Western|\n|     Hemingway|         Romance|War|\n|          null|    Romance|Thriller|\n|      artistic|Romance|Sci-Fi|Th...|\n|         artsy|Romance|Sci-Fi|Th...|\n|          null|Romance|Sci-Fi|Th...|\n|     dreamlike|Romance|Sci-Fi|Th...|\n|   atmospheric|Romance|Sci-Fi|Th...|\n|existentialism|Romance|Sci-Fi|Th...|\n|     Beautiful|Romance|Sci-Fi|Th...|\n|          null|      Romance|Sci-Fi|\n|          null|             Romance|\n+--------------+--------------------+\nonly showing top 20 rows\n\nSaved Successfully\n"}], "source": "# What is the predominant tag per genre and the most tagged genres?\nQuery = \"\"\" WITH T1 AS \n                ( SELECT T.tag AS Tag, M.genres AS Genre, COUNT(*) AS Counts,\n                DENSE_RANK() OVER(Partition BY M.genres ORDER BY COUNT(*) DESC) AS Rank\n                FROM Tags T \n                RIGHT JOIN Movies M \n                ON M.movieId = T.movieId \n                GROUP BY Genre,Tag )\n                \n                SELECT T1.Tag, T1.Genre FROM T1 WHERE Rank = 1\n                ORDER BY T1.Genre DESC \"\"\"\n\nOutput = Spark.sql(Query)\nOutput.show()\n\n# Write data in HDFS into single file\nOutput.coalesce(1).write.mode(\"overwrite\").format(\"csv\").options(header = True,delimiter = ',').save(\"/Spark/Assignment2/Solution/Frequency_Based_Genre_Per_Tag.csv\")\n\nprint(\"Saved Successfully\")\n"}, {"cell_type": "markdown", "id": "9c4bfb09-02da-4769-ac01-c46deab618fa", "metadata": {}, "source": "# 13. What are the most predominant (popularity based) movies? save the data in a single CSV file in HDFS"}, {"cell_type": "code", "execution_count": 148, "id": "8eeb29aa-b124-46b9-a0cf-5e2c8284f17c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+-------------+\n|               Title|Total_Ratings|\n+--------------------+-------------+\n| Forrest Gump (1994)|          329|\n|Shawshank Redempt...|          317|\n| Pulp Fiction (1994)|          307|\n|Silence of the La...|          279|\n|  Matrix, The (1999)|          278|\n|Star Wars: Episod...|          251|\n|Jurassic Park (1993)|          238|\n|   Braveheart (1995)|          237|\n|Terminator 2: Jud...|          224|\n|Schindler's List ...|          220|\n|   Fight Club (1999)|          218|\n|    Toy Story (1995)|          215|\n|Star Wars: Episod...|          211|\n|American Beauty (...|          204|\n|Usual Suspects, T...|          204|\n|Seven (a.k.a. Se7...|          203|\n|Independence Day ...|          202|\n|    Apollo 13 (1995)|          201|\n|Raiders of the Lo...|          200|\n|Lord of the Rings...|          198|\n+--------------------+-------------+\nonly showing top 20 rows\n\nSaved Successfully\n"}], "source": "# What are the most predominant (popularity based) movies?\n\nQuery = \"\"\" SELECT M.title AS Title, COUNT(R.rating) as Total_Ratings\n            FROM Movies M \n            INNER JOIN Ratings R \n            ON M.movieId = R.movieId \n            GROUP BY Title\n            ORDER BY Total_Ratings DESC \"\"\"\n\nOutput = Spark.sql(Query)\nOutput.show()\n\n# Write data in HDFS into single file\nOutput.coalesce(1).write.mode(\"overwrite\").format(\"csv\").options(header = True,delimiter = ',').save(\"/Spark/Assignment2/Solution/Most_Popular_Movies.csv\")\n\nprint(\"Saved Successfully\")\n"}, {"cell_type": "markdown", "id": "17dbeb45-02b5-4a68-8ce2-5fda0b3267b5", "metadata": {}, "source": "# 14. Top 10 movies in terms of average rating (provided more than 30 users reviewed them) save the data in a single CSV file in HDFS"}, {"cell_type": "code", "execution_count": 149, "id": "f9f3c2bc-05b3-40b6-b91f-93b62a1f81b5", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+-------+-----------------+--------------------+\n|               title|MovieId|   Average_Rating|              genres|\n+--------------------+-------+-----------------+--------------------+\n|Shawshank Redempt...|    318|4.429022082018927|         Crime|Drama|\n|Lawrence of Arabi...|   1204|              4.3| Adventure|Drama|War|\n|Godfather, The (1...|    858|        4.2890625|         Crime|Drama|\n|   Fight Club (1999)|   2959|4.272935779816514|Action|Crime|Dram...|\n|Cool Hand Luke (1...|   1276|4.271929824561403|               Drama|\n|Dr. Strangelove o...|    750|4.268041237113402|          Comedy|War|\n|  Rear Window (1954)|    904|4.261904761904762|    Mystery|Thriller|\n|Godfather: Part I...|   1221| 4.25968992248062|         Crime|Drama|\n|Departed, The (2006)|  48516|4.252336448598131|Crime|Drama|Thriller|\n|Manchurian Candid...|   1267|             4.25|  Crime|Thriller|War|\n|   Goodfellas (1990)|   1213|             4.25|         Crime|Drama|\n|   Casablanca (1942)|    912|             4.24|       Drama|Romance|\n|Dark Knight, The ...|  58559|4.238255033557047|Action|Crime|Dram...|\n|Usual Suspects, T...|     50|4.237745098039215|Crime|Mystery|Thr...|\n|Princess Bride, T...|   1197|4.232394366197183|Action|Adventure|...|\n|Star Wars: Episod...|    260|4.231075697211155|Action|Adventure|...|\n|Schindler's List ...|    527|            4.225|           Drama|War|\n|Boondock Saints, ...|   3275| 4.22093023255814|Action|Crime|Dram...|\n|Apocalypse Now (1...|   1208|4.219626168224299|    Action|Drama|War|\n|American History ...|   2329|4.217054263565892|         Crime|Drama|\n+--------------------+-------+-----------------+--------------------+\nonly showing top 20 rows\n\nSaved Successfully\n"}], "source": "# Top 10 movies in terms of average rating (provided more than 30 users reviewed them)\n\nQuery = \"\"\" WITH T1 AS \n                ( SELECT movieId, COUNT(DISTINCT userId) AS Rating_Counts\n                FROM Ratings\n                GROUP BY movieId\n                HAVING Rating_Counts >= 30\n                ORDER BY Rating_Counts DESC ),\n            T2 AS \n                ( SELECT T1.movieId as MovieId, AVG(R.rating) AS Average_Rating FROM\n                T1 INNER JOIN Ratings R ON \n                T1.movieId = R.movieId\n                GROUP BY T1.movieId\n                ORDER BY AVG(R.rating) DESC)\n            SELECT M.title,M.MovieId,T2.Average_Rating,M.genres FROM T2\n            INNER JOIN Movies M \n            ON M.movieId =  T2.movieId\n            ORDER BY Average_Rating DESC \"\"\"\n\nOutput = Spark.sql(Query)\nOutput.show()\n\n# Write data in HDFS into single file\nOutput.coalesce(1).write.mode(\"overwrite\").format(\"csv\").options(header = True,delimiter = ',').save(\"/Spark/Assignment2/Solution/Top_10_Average_Ratings_Movies.csv\")\n\nprint(\"Saved Successfully\")"}, {"cell_type": "code", "execution_count": null, "id": "5bbc4486-c7ed-424c-8e7b-636ac59c1aee", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 5}